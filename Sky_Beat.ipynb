{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAMEHAMEHA-05/Sky-Beat/blob/main/Sky_Beat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM1qPNGdzPBx"
      },
      "outputs": [],
      "source": [
        "!pip install cv2\n",
        "!pip install numpy\n",
        "!pip install random\n",
        "!pip install time\n",
        "!pip install statistics\n",
        "!pip install keras.models\n",
        "!pip install utils\n",
        "!pip install firestore\n",
        "!pip install utilx\n",
        "!pip install oauth2\n",
        "!pip install numpy\n",
        "!pip install SpeechRecognition\n",
        "!pip install textblob\n",
        "!pip install wavio\n",
        "!pip install ffmpeg-python\n",
        "!pip install spotify==0.4.8\n",
        "!pip install spotipy==2.4.4\n",
        "!pip install python-oauth2\n",
        "!pip install delegator\n",
        "!pip install spotify_local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXt7nhbZzVV6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBn1xTxbzVw-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from statistics import mode\n",
        "import os\n",
        "os.chdir(\"/content/\")\n",
        "from datasets import *\n",
        "import inference\n",
        "from inference import draw_text\n",
        "from inference import draw_bounding_box\n",
        "from inference import apply_offsets\n",
        "from inference import load_detection_model\n",
        "import preprocessor\n",
        "import random\n",
        "import time\n",
        "import spotipy #as sp\n",
        "import spotify\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import sys\n",
        "from python_utils import*\n",
        "import os\n",
        "from spotify_local import SpotifyLocal\n",
        "import spotipy.util as utilx\n",
        "import oauth2\n",
        "\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import math, random\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import speech_recognition\n",
        "from textblob import TextBlob\n",
        "import wavio\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import spotify\n",
        "import sys\n",
        "import spotipy\n",
        "from python_utils import*\n",
        "import os\n",
        "from spotify_local import SpotifyLocal\n",
        "import spotipy.util as utilx\n",
        "import oauth2\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Capturing\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  print(filename)\n",
        "  return filename\n",
        "\n",
        "filename = take_photo()\n",
        "\n",
        "#Facial\n",
        "i=0\n",
        "USE_WEBCAM = True\n",
        "Emotion_score_array=[0.5]*30\n",
        "\n",
        "emotion_model_path = 'emotion_model.hdf5'\n",
        "emotion_labels = get_labels('fer2013')\n",
        "\n",
        "\n",
        "frame_window = 10\n",
        "emotion_offsets = (20, 40)\n",
        "\n",
        "# loading models\n",
        "face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "emotion_classifier = load_model('/content/emotion_model.hdf5')\n",
        "\n",
        "\n",
        "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
        "\n",
        "\n",
        "emotion_window = []\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "while 1<10 :\n",
        "\n",
        "\n",
        "\n",
        "    image = cv2.imread(\"/content/photo.jpg\")\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5,\n",
        "    minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "\n",
        "    for face_coordinates in faces:\n",
        "\n",
        "        x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
        "        gray_face = gray_image[y1:y2, x1:x2]\n",
        "\n",
        "        try:\n",
        "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
        "\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "            gray_face = preprocess_input(gray_face, True)\n",
        "            gray_face = np.expand_dims(gray_face, 0)\n",
        "            gray_face = np.expand_dims(gray_face, -1)\n",
        "            emotion_prediction = emotion_classifier.predict(gray_face)\n",
        "            emotion_probability = np.max(emotion_prediction)\n",
        "            emotion_label_arg = np.argmax(emotion_prediction)\n",
        "            emotion_text = emotion_labels[emotion_label_arg]\n",
        "            emotion_window.append(emotion_text)\n",
        "            print(\"g\")\n",
        "\n",
        "        # if len(emotion_window) > frame_window:\n",
        "        #     emotion_window.pop(0)\n",
        "        #\n",
        "        try:\n",
        "            emotion_mode = mode(emotion_window)\n",
        "            print(\"g\")\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        if emotion_text == 'angry':\n",
        "            color = emotion_probability * np.asarray((255, 0, 0))\n",
        "            Emotion_score_array.pop(0)\n",
        "            Emotion_score_array.append(.22)\n",
        "        elif emotion_text == 'sad':\n",
        "            color = emotion_probability * np.asarray((0, 0, 255))\n",
        "            Emotion_score_array.pop(0)\n",
        "            Emotion_score_array.append(-0.4)\n",
        "        elif emotion_text == 'happy':\n",
        "            color = emotion_probability * np.asarray((255, 255, 0))\n",
        "            Emotion_score_array.pop(0)\n",
        "            Emotion_score_array.append(0.9)\n",
        "        elif emotion_text == 'surprise':\n",
        "            color = emotion_probability * np.asarray((0, 255, 255))\n",
        "            Emotion_score_array.pop(0)\n",
        "            Emotion_score_array.append(.61)\n",
        "        elif emotion_text == 'disgust':\n",
        "            color = emotion_probability * np.asarray((0, 255, 0))\n",
        "            Emotion_score_array.pop(0)\n",
        "            Emotion_score_array.append(.001)\n",
        "        elif emotion_text == 'fear':\n",
        "            color = emotion_probability * np.asarray((0, 255, 0))\n",
        "            Emotion_score_array.pop(0)\n",
        "            Emotion_score_array.append(.1)\n",
        "        else:\n",
        "            color = emotion_probability * np.asarray((0, 255, 0))\n",
        "            print(\"i\")\n",
        "\n",
        "        color = color.astype(int)\n",
        "        color = color.tolist()\n",
        "\n",
        "        draw_bounding_box(face_coordinates, rgb_image, color)\n",
        "        draw_text(face_coordinates, rgb_image, emotion_mode,\n",
        "                  color, 0, -45, 1, 1)\n",
        "\n",
        "    bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
        "    #cv2.imshow('window_frame', bgr_image)\n",
        "    # print(Emotion_score_array)\n",
        "    i=i+1\n",
        "\n",
        "    if i==100:\n",
        "        Emotion_score=np.array(Emotion_score_array)\n",
        "        a=np.mean(Emotion_score)+random.uniform(0.001,0.07)\n",
        "        a=round(a,2)\n",
        "        if a<=0.1:\n",
        "            a=0.1\n",
        "        if a>=0.99:\n",
        "            a=0.99\n",
        "        print(a)\n",
        "        #timestamp = int(time.time())\n",
        "        #fs(a,timestamp,u'actual')\n",
        "        #appreciation\n",
        "        if a<=0.65:\n",
        "            ap=a+random.uniform(0.01,0.09)\n",
        "        else:\n",
        "            ap=a\n",
        "        print(round(ap,2))\n",
        "        # fs(round(ap,2),timestamp,u'appreciation')\n",
        "        i=0\n",
        "\n",
        "        def get_audio():\n",
        "          display(HTML(AUDIO_HTML))\n",
        "          data = eval_js(\"data\")\n",
        "          binary = b64decode(data.split(',')[1])\n",
        "\n",
        "          process = (ffmpeg\n",
        "            .input('pipe:0')\n",
        "            .output('pipe:1', format='wav')\n",
        "            .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "          )\n",
        "          output, err = process.communicate(input=binary)\n",
        "\n",
        "          riff_chunk_size = len(output) - 8\n",
        "          # Break up the chunk size into four bytes, held in b.\n",
        "          q = riff_chunk_size\n",
        "          b = []\n",
        "          for i in range(4):\n",
        "              q, r = divmod(q, 256)\n",
        "              b.append(r)\n",
        "\n",
        "          # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "          riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "          sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "          return audio, sr\n",
        "\n",
        "        xyz = get_audio()\n",
        "        print(xyz[0])\n",
        "        fs = 44100\n",
        "        seconds = 5\n",
        "        os.chdir(\"/content/\")\n",
        "        y = (np.iinfo(np.int32).max * (xyz[0]/np.abs(xyz[0]).max())).astype(np.int32)  # You were passing the data as float but speech_recognition takes\n",
        "        wavio.write(\"output.wav\", xyz[0], fs ,sampwidth=2)\n",
        "\n",
        "# RECOGNITION\n",
        "        import speech_recognition as sr\n",
        "        r=sr.Recognizer()\n",
        "        recording = sr.AudioFile(\"/content/output.wav\")\n",
        "        with recording as source :\n",
        "          audio1=r.record(source)\n",
        "\n",
        "          try:\n",
        "            state = r.recognize_google(audio1,language=\"en-GB\")\n",
        "          except:\n",
        "            print(\"I can't get you. Please try again\")\n",
        "            break\n",
        "          if state.lower()==\"stop\" :\n",
        "            break\n",
        "\n",
        "        print(state)\n",
        "        feedback = state\n",
        "        blob=TextBlob(feedback)\n",
        "        #print(blob.sentiment)\n",
        "\n",
        "        p,s = blob.sentiment\n",
        "        e_ = p*s\n",
        "        e = (abs(-0.5-(e_/2)))\n",
        "        print(e)\n",
        "        m = (ap+e)/2\n",
        "        print(ap)\n",
        "        print(e)\n",
        "#SPOTIFY\n",
        "        mood = m\n",
        "        print(\"mood = \",mood)\n",
        "        client_id = 'your-client-id-here'\n",
        "        client_secret = 'your-client-secret-here'\n",
        "        redirect_uri = 'your-redirect-url-here'\n",
        "        scope = 'user-library-read user-top-read playlist-modify-public user-follow-read'\n",
        "        username= 'your-username-here'\n",
        "        token = utilx.prompt_for_user_token(username,scope,client_id=client_id,client_secret=client_secret,redirect_uri=redirect_uri)\n",
        "        if token:\n",
        "\n",
        "        #Step 1. Authenticating Spotipy\n",
        "\n",
        "          def authenticate_spotify():\n",
        "            print('...connecting to Spotify')\n",
        "            sp = spotipy.Spotify(auth=token)\n",
        "            return sp\n",
        "\n",
        "        #Step 2. Creating a list of your favorite artists\n",
        "\n",
        "          def aggregate_top_artists(sp):\n",
        "            print('...getting your top artists')\n",
        "            top_artists_name = []\n",
        "            top_artists_uri = []\n",
        "\n",
        "            ranges = ['short_term', 'medium_term', 'long_term']\n",
        "            for r in ranges:\n",
        "              top_artists_all_data = sp.current_user_top_artists(limit=50, time_range= r)\n",
        "              top_artists_data = top_artists_all_data['items']\n",
        "              for artist_data in top_artists_data:\n",
        "                if artist_data[\"name\"] not in top_artists_name:\n",
        "                  top_artists_name.append(artist_data['name'])\n",
        "                  top_artists_uri.append(artist_data['uri'])\n",
        "\n",
        "            followed_artists_all_data = sp.current_user_followed_artists(limit=50)\n",
        "            followed_artists_data = (followed_artists_all_data['artists'])\n",
        "            for artist_data in followed_artists_data[\"items\"]:\n",
        "              if artist_data[\"name\"] not in top_artists_name:\n",
        "                top_artists_name.append(artist_data['name'])\n",
        "                top_artists_uri.append(artist_data['uri'])\n",
        "            return top_artists_uri\n",
        "\n",
        "\n",
        "        #Step 3. For each of the artists, get a set of tracks for each artist\n",
        "\n",
        "          def aggregate_top_tracks(sp, top_artists_uri):\n",
        "            print(\"...getting top tracks\")\n",
        "            top_tracks_uri = []\n",
        "            for artist in top_artists_uri:\n",
        "              top_tracks_all_data = sp.artist_top_tracks(artist)\n",
        "              top_tracks_data = top_tracks_all_data['tracks']\n",
        "              for track_data in top_tracks_data:\n",
        "                top_tracks_uri.append(track_data['uri'])\n",
        "            return top_tracks_uri\n",
        "\n",
        "        # Step 4. From top tracks, select tracks that are within a certain mood range\n",
        "\n",
        "          def select_tracks(sp, top_tracks_uri):\n",
        "\n",
        "            print(\"...selecting tracks\")\n",
        "            selected_tracks_uri = []\n",
        "\n",
        "            def group(seq, size):\n",
        "              return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
        "\n",
        "            random.shuffle(top_tracks_uri)\n",
        "            for tracks in list(group(top_tracks_uri, 50)):\n",
        "              tracks_all_data = sp.audio_features(tracks)\n",
        "              for track_data in tracks_all_data:\n",
        "                try:\n",
        "                  if mood < 0.10:\n",
        "                    if (0 <= track_data[\"valence\"] <= (mood + 0.15)\n",
        "                    and track_data[\"danceability\"] <= (mood*8)\n",
        "                    and track_data[\"energy\"] <= (mood*10)):\n",
        "                      selected_tracks_uri.append(track_data[\"uri\"])\n",
        "                  elif 0.10 <= mood < 0.25:\n",
        "                    if ((mood - 0.075) <= track_data[\"valence\"] <= (mood + 0.075)\n",
        "                    and track_data[\"danceability\"] <= (mood*4)\n",
        "                    and track_data[\"energy\"] <= (mood*5)):\n",
        "                      selected_tracks_uri.append(track_data[\"uri\"])\n",
        "                  elif 0.25 <= mood < 0.50:\n",
        "                    if ((mood - 0.05) <= track_data[\"valence\"] <= (mood + 0.05)\n",
        "                    and track_data[\"danceability\"] <= (mood*1.75)\n",
        "                    and track_data[\"energy\"] <= (mood*1.75)):\n",
        "                      selected_tracks_uri.append(track_data[\"uri\"])\n",
        "                  elif 0.50 <= mood < 0.75:\n",
        "                    if ((mood - 0.075) <= track_data[\"valence\"] <= (mood + 0.075)\n",
        "                    and track_data[\"danceability\"] >= (mood/2.5)\n",
        "                    and track_data[\"energy\"] >= (mood/2)):\n",
        "                      selected_tracks_uri.append(track_data[\"uri\"])\n",
        "                  elif 0.75 <= mood < 0.90:\n",
        "                    if ((mood - 0.075) <= track_data[\"valence\"] <= (mood + 0.075)\n",
        "                    and track_data[\"danceability\"] >= (mood/2)\n",
        "                    and track_data[\"energy\"] >= (mood/1.75)):\n",
        "                      selected_tracks_uri.append(track_data[\"uri\"])\n",
        "                  elif mood >= 0.90:\n",
        "                    if ((mood - 0.15) <= track_data[\"valence\"] <= 1\n",
        "                    and track_data[\"danceability\"] >= (mood/1.75)\n",
        "                    and track_data[\"energy\"] >= (mood/1.5)):\n",
        "                      selected_tracks_uri.append(track_data[\"uri\"])\n",
        "                except TypeError as te:\n",
        "                  continue\n",
        "\n",
        "            return selected_tracks_uri\n",
        "\n",
        "        # Step 5. From these tracks, create a playlist for user\n",
        "          def generateOTP() :\n",
        "\n",
        "            # Declare a digits variable\n",
        "            # which stores all digits\n",
        "            digits = \"0123456789\"\n",
        "            OTP = \"\"\n",
        "\n",
        "          # length of password can be chaged\n",
        "          # by changing value in range\n",
        "            for i in range(3) :\n",
        "                OTP += digits[math.floor(random.random() * 10)]\n",
        "\n",
        "            return OTP\n",
        "\n",
        "          def create_playlist(sp, selected_tracks_uri):\n",
        "\n",
        "            print(\"...creating playlist\")\n",
        "            user_all_data = sp.current_user()\n",
        "            user_id = user_all_data[\"id\"]\n",
        "            opt = generateOTP()\n",
        "            print(\"Name of new playlist:\", opt+\"_\"+str(int(m*100)))\n",
        "            playlist_all_data = sp.user_playlist_create(user_id, opt+\"_\"+str(int(m*100)) )#\"Your mood= \" + str(mood) + \" @\" + current_time + \", \" + d4)\n",
        "            playlist_id = playlist_all_data[\"id\"]\n",
        "\n",
        "            random.shuffle(selected_tracks_uri)\n",
        "            sp.user_playlist_add_tracks(user_id, playlist_id, selected_tracks_uri[0:30])\n",
        "\n",
        "\n",
        "          spotify_auth = authenticate_spotify()\n",
        "          top_artists = aggregate_top_artists(spotify_auth)\n",
        "          top_tracks = aggregate_top_tracks(spotify_auth, top_artists)\n",
        "          selected_tracks = select_tracks(spotify_auth, top_tracks)\n",
        "          create_playlist(spotify_auth, selected_tracks)\n",
        "\n",
        "          filename = take_photo()\n",
        "          print(\"-----------------------------------------------------------------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}